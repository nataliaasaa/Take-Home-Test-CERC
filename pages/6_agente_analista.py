import streamlit as st
import google.generativeai as genai
import os
import hashlib
from utils.context_builder import build_risk_context  # Mant√©m sua fun√ß√£o existente

st.title("ü§ñ Risk Analyst AI (Google Gemini)")


# # =============== DEBUG OPCIONAL (remova em produ√ß√£o) ===============
# if st.checkbox("üîç Mostrar debug de secrets", key="debug"):
#     st.write("st.secrets existe?", hasattr(st, 'secrets'))
#     if hasattr(st, 'secrets'):
#         st.write("Chaves em st.secrets:", list(st.secrets.keys()))
#         st.write("google em st.secrets?", "google" in st.secrets)
#         if "google" in st.secrets:
#             st.write("API_KEY presente?", "GOOGLE_API_KEY" in st.secrets["google"])

# =============== VALIDA√á√ÉO DE DADOS ===============
df = st.session_state.get("final_results_df")
if df is None:
    st.warning("‚ö†Ô∏è Execute a predi√ß√£o na p√°gina 'Predi√ß√£o' antes de acessar esta an√°lise.")
    st.page_link("pages/5_Predicao.py", label="Ir para p√°gina de Predi√ß√£o", icon="‚û°Ô∏è")
    st.stop()

# =============== SELE√á√ÉO DE EMPRESA ===============
company = st.selectbox(
    "üîç Selecione uma empresa para an√°lise detalhada",
    ["Todas"] + sorted(df["Name"].dropna().unique().tolist()),
    help="Filtre os resultados para focar em uma empresa espec√≠fica"
)

# =============== CONFIGURA√á√ÉO DA API ===============
try:
    # Prioriza Streamlit Secrets (recomendado para produ√ß√£o)
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    elif os.getenv("GOOGLE_API_KEY"):
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    else:
        st.error("üîë Chave API n√£o encontrada! Configure em:")
        st.code("Secrets do Streamlit: GOOGLE_API_KEY\nOU vari√°vel de ambiente: GOOGLE_API_KEY")
        st.stop()
except Exception as e:
    st.error(f"‚ùå Erro na configura√ß√£o da API: {str(e)}")
    st.stop()

# =============== CONSTRU√á√ÉO DE CONTEXTO ===============
try:
    context = build_risk_context(
        df,
        None if company == "Todas" else company
    )
    
    # Valida√ß√£o cr√≠tica do contexto
    if not context or len(context.strip()) < 20:
        st.error("‚ö†Ô∏è Contexto de risco vazio ou inv√°lido. Verifique os dados de predi√ß√£o.")
        st.stop()
except Exception as e:
    st.error(f"‚ùå Erro ao construir contexto: {str(e)}")
    st.stop()

# =============== RESET DE HIST√ìRICO AO MUDAR CONTEXTO ===============
context_hash = hashlib.md5(context.encode()).hexdigest()
if "context_hash" not in st.session_state or st.session_state.context_hash != context_hash:
    st.session_state.context_hash = context_hash
    st.session_state.messages = []
    st.session_state.chat_session = None  # For√ßa nova sess√£o

# =============== INSTRU√á√ÉO DO SISTEMA (OTIMIZADA) ===============
SYSTEM_INSTRUCTION = f"""Voc√™ √© um analista s√™nior de risco de cr√©dito corporativo do Banco Central.

REGRAS ESTRITAS:
1. USE EXCLUSIVAMENTE os dados do contexto abaixo. NUNCA invente n√∫meros, nomes ou m√©tricas.
2. Se informa√ß√£o n√£o existir no contexto: "‚ö†Ô∏è Dado n√£o dispon√≠vel na an√°lise realizada."
3. Responda com clareza para comit√™ de cr√©dito: destaque risco alto/m√©dio/baixo, principais drivers e recomenda√ß√µes objetivas.
4. Use prioritariamente a se√ß√£o "EMPRESA SELECIONADA ‚Äì AN√ÅLISE DETALHADA" quando o usu√°rio perguntar sobre uma empresa espec√≠fica.
5. Formate respostas com:
   - üìå Resumo executivo (1 linha)
   - üîç An√°lise detalhada (t√≥picos)
   - üí° Recomenda√ß√£o pr√°tica
6. Mantenha linguagem t√©cnica mas acess√≠vel (evite jarg√µes excessivos).

CONTEXTO DOS DADOS (ATUALIZADO PARA: {company if company != 'Todas' else 'TODAS AS EMPRESAS'}):
{context}"""

# =============== INICIALIZA√á√ÉO DO MODELO ===============
try:
    if "gemini_model" not in st.session_state:

        st.session_state.gemini_model = genai.GenerativeModel(
            model_name="gemini-flash-latest",
            system_instruction=SYSTEM_INSTRUCTION,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=2048,
                top_p=0.8,
                top_k=40
            )
        )
    
    # Cria nova sess√£o de chat se necess√°rio
    if st.session_state.chat_session is None:
        st.session_state.chat_session = st.session_state.gemini_model.start_chat(history=[])
except Exception as e:
    st.error(f"‚ùå Falha ao inicializar modelo: {str(e)}")
    st.stop()

# =============== INTERFACE DE CHAT ===============
st.subheader("üí¨ Conversa com Analista de Risco")
st.caption(f"Contexto carregado: {company} | Modelo: Gemini Flash")

# Exibe hist√≥rico
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar="üë§" if msg["role"] == "user" else "ü§ñ"):
        st.write(msg["content"])

# Input do usu√°rio
if prompt := st.chat_input("Ex: 'Qual o principal risco desta empresa?', 'Compare com a m√©dia do setor', 'Justifique a classifica√ß√£o'"):
    # Adiciona mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="üë§"):
        st.write(prompt)
    
    # Processa resposta
    with st.chat_message("assistant", avatar="ü§ñ"):
        with st.spinner("üîç Analisando dados de risco..."):
            try:
                response = st.session_state.chat_session.send_message(prompt)
                if not response.text.strip():
                    raise ValueError("Resposta vazia do modelo")
                
                st.write(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
                # Feedback sutil de uso
                st.caption(f"‚úÖ Resposta gerada com {len(response.text)} caracteres")
                
            except Exception as e:
                error_msg = (
                    "‚ö†Ô∏è Limite de tokens excedido. Tente perguntas mais objetivas." if "429" in str(e) or "token" in str(e).lower() else
                    "‚ö†Ô∏è Erro tempor√°rio na API. Tente novamente em 10 segundos." if "503" in str(e) else
                    f"‚ùå Erro inesperado: {str(e)}"
                )
                st.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

# =============== DICA CONTEXTUAL ===============
with st.expander("üí° Dicas para melhores respostas"):
    st.markdown("""
    - **Seja espec√≠fico**: "Qual o risco de inadimpl√™ncia para a empresa X?"  
    - **Pe√ßa compara√ß√µes**: "Como esta empresa se compara √† m√©dia do setor?"  
    - **Solicite a√ß√µes**: "Quais documentos complementares voc√™ recomenda analisar?"  
    - **Evite perguntas gen√©ricas**: O modelo foca APENAS nos dados do contexto carregado.
    """)
